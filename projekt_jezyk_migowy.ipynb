{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rozpoznawanie(obraz, model):\n",
    "    obraz = cv2.cvtColor(obraz, cv2.COLOR_BGR2RGB)\n",
    "    obraz.flags.writeable = False\n",
    "    wynik = model.process(obraz)\n",
    "    obraz.flags.writeable = True                   \n",
    "    obraz = cv2.cvtColor(obraz, cv2.COLOR_RGB2BGR)\n",
    "    return obraz, wynik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def szkielet(obraz, wyniki):\n",
    "    mp_drawing.draw_landmarks(obraz, wyniki.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(obraz, wyniki.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "sciezka = os.path.join('dane')  \n",
    "\n",
    "gesty = np.array(['czesc','dziekuje'])\n",
    "\n",
    "liczba_sekwencji = 30\n",
    "\n",
    "dlugosc_sekwencji = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zwroc_punkty(wyniki):\n",
    "    lewa = np.zeros(21*3)\n",
    "    prawa = np.zeros(21*3)\n",
    "\n",
    "    if wyniki.left_hand_landmarks:\n",
    "        lewa = np.array([[res.x, res.y, res.z] for res in wyniki.left_hand_landmarks.landmark]).flatten()\n",
    "\n",
    "    if wyniki.right_hand_landmarks:\n",
    "        prawa = np.array([[res.x, res.y, res.z] for res in wyniki.right_hand_landmarks.landmark]).flatten()\n",
    "\n",
    "    return np.concatenate([ lewa, prawa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nazwy_mapa = {nazwa:num for num, nazwa in enumerate(gesty)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'czesc': 0, 'dziekuje': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nazwy_mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sekwencje, nazwy = [], []\n",
    "for akcja in gesty:\n",
    "    for sekwencja in range(liczba_sekwencji):\n",
    "        okno = []\n",
    "        for nr_klatki in range(dlugosc_sekwencji):\n",
    "            res = np.load(os.path.join(sciezka, akcja, str(sekwencja), \"{}.npy\".format(nr_klatki)))\n",
    "            okno.append(res)\n",
    "        sekwencje.append(okno)\n",
    "        nazwy.append(nazwy_mapa[akcja])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sekwencje)\n",
    "y = to_categorical(nazwy).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 30, 126)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,\n",
    "                                              stratify=y,random_state=1 )\n",
    "X_valid,X_test,y_valid,y_test=train_test_split(X_test,y_test,test_size=0.5,\n",
    "                                              stratify=y_test,random_state=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stworz_model(X_train, y_train, X_test, y_test):\n",
    "\tl_krokow, l_featerow, l_outputow = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(l_krokow,l_featerow)))\n",
    "\tmodel.add(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "\tmodel.add(tf.keras.layers.Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu'))\n",
    "\tmodel.add(Dense(l_outputow, activation='softmax'))\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=stworz_model(X_train,y_train, X_test,  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7587 - accuracy: 0.4444 - val_loss: 0.4421 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4675 - accuracy: 0.5278 - val_loss: 0.3231 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2766 - accuracy: 0.9722 - val_loss: 0.2378 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1655 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.2958e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.4609e-04 - accuracy: 1.0000 - val_loss: 9.7403e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.3834e-05 - accuracy: 1.0000 - val_loss: 5.2427e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 2.4890e-05 - accuracy: 1.0000 - val_loss: 2.9126e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 9.2749e-06 - accuracy: 1.0000 - val_loss: 1.6713e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.5597e-06 - accuracy: 1.0000 - val_loss: 9.8967e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2.8411e-06 - accuracy: 1.0000 - val_loss: 6.0462e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2418e-06 - accuracy: 1.0000 - val_loss: 3.8085e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7751e-07 - accuracy: 1.0000 - val_loss: 2.4804e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.4769e-07 - accuracy: 1.0000 - val_loss: 1.6599e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,\n",
    "                  validation_data=(X_valid,y_valid),\n",
    "                  batch_size=128,\n",
    "                  epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - loss: 2.3671e-05 - accuracy: 1.0000\n",
      "Test score: 2.367142769799102e-05\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score,acc=model.evaluate(X_test,y_test)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolory = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prawdopodobienstwo(res, gesty, klatka_wejsciowa, kolory):\n",
    "    klatka_wyjsciowa = klatka_wejsciowa.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(klatka_wyjsciowa, (0,60+num*40), ((prob*100).astype(int), 90+num*40), kolory[num], -1)\n",
    "        cv2.putText(klatka_wyjsciowa, gesty[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return klatka_wyjsciowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 208ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "czesc\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "czesc\n"
     ]
    }
   ],
   "source": [
    "sekwencja = []\n",
    "zdanie = []\n",
    "prog = 0.8\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        wartosc, klatka = cap.read()\n",
    "\n",
    "        obraz, wyniki = rozpoznawanie(klatka, holistic)\n",
    "        \n",
    "        szkielet(obraz, wyniki)\n",
    "        \n",
    "        keypoints = zwroc_punkty(wyniki)\n",
    "        \n",
    "        sekwencja.append(keypoints)\n",
    "        sekwencja = sekwencja[-30:]\n",
    "        \n",
    "        if len(sekwencja) == 30:\n",
    "            res = model.predict(np.expand_dims(sekwencja, axis=0))[0]\n",
    "            print(gesty[np.argmax(res)])\n",
    "            \n",
    "            \n",
    "            if res[np.argmax(res)] > prog: \n",
    "                if len(zdanie) > 0: \n",
    "                    if gesty[np.argmax(res)] != zdanie[-1]:\n",
    "                        zdanie.append(gesty[np.argmax(res)])\n",
    "                else:\n",
    "                    zdanie.append(gesty[np.argmax(res)])\n",
    "\n",
    "            if len(zdanie) > 5: \n",
    "                zdanie = zdanie[-5:]\n",
    "\n",
    "            obraz = prawdopodobienstwo(res, gesty, cv2.flip(obraz, 1), kolory)\n",
    "            \n",
    "        cv2.rectangle(obraz, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(obraz, ' '.join(zdanie), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow('Jezyk migowy', obraz)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a782e78c516a0591e27701d1f830b917a27108ff0d49951d1f9790dfad5ff2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
